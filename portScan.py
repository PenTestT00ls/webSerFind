#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆç«¯å£æ‰«æè„šæœ¬ - è‡ªåŠ¨HTTPæ¢æµ‹
è‡ªåŠ¨æ¢æµ‹æ‰€æœ‰å¼€æ”¾ç«¯å£çš„WebæœåŠ¡å¹¶æå–ç½‘é¡µæ ‡é¢˜
"""

import socket
import sys
import argparse
import time
from datetime import datetime
import requests
import urllib3
from concurrent.futures import ThreadPoolExecutor, as_completed
import signal
from bs4 import BeautifulSoup
import re

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# å¸¸è§çš„HTTPç«¯å£åˆ—è¡¨
COMMON_HTTP_PORTS = {80, 443, 8080, 8000, 3000, 8888, 8443, 8081, 8090, 9000, 5000, 5001}
DEFAULT_PORTS = "80,443,8080,8000,3000,8888,9000,5000,8081,8090,5010,5011,8091,8085,8099,8778,8891,28001,28002,28003,28004,50078,60080,60081"

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='è‡ªåŠ¨HTTPæ¢æµ‹ç«¯å£æ‰«æå™¨',
        usage='%(prog)s target [-p PORTS] [-t THREADS] [-o OUTPUT]',
        epilog='ç¤ºä¾‹: portscan.py 39.153.159.91 -p 1-1000 -t 100 -o web_results.txt'
    )
    
    parser.add_argument('target', help='ç›®æ ‡IPåœ°å€æˆ–åŸŸå')
    parser.add_argument('-p', '--ports', default=DEFAULT_PORTS, 
                       help=f'ç«¯å£èŒƒå›´ (é»˜è®¤: {DEFAULT_PORTS})')
    parser.add_argument('-t', '--threads', type=int, default=50,
                       help='æ‰«æçº¿ç¨‹æ•° (é»˜è®¤: 50)')
    parser.add_argument('-T', '--threads-http', type=int, default=20,
                       help='HTTPæ¢æµ‹çº¿ç¨‹æ•° (é»˜è®¤: 20)')
    parser.add_argument('-o', '--output', help='è¾“å‡ºç»“æœåˆ°æ–‡ä»¶')
    parser.add_argument('--timeout-scan', type=float, default=2.0,
                       help='ç«¯å£æ‰«æè¶…æ—¶æ—¶é—´(ç§’) (é»˜è®¤: 2.0)')
    parser.add_argument('--timeout-http', type=float, default=5.0,
                       help='HTTPè¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) (é»˜è®¤: 5.0)')
    parser.add_argument('--no-verify', action='store_true',
                       help='ä¸éªŒè¯SSLè¯ä¹¦ (é»˜è®¤ä¸éªŒè¯)')
    parser.add_argument('--force-http', action='store_true',
                       help='å¼ºåˆ¶å¯¹æ‰€æœ‰ç«¯å£è¿›è¡ŒHTTPæ¢æµ‹')
    parser.add_argument('--show-all', action='store_true',
                       help='æ˜¾ç¤ºæ‰€æœ‰ç«¯å£ï¼ŒåŒ…æ‹¬éHTTPæœåŠ¡')
    
    return parser.parse_args()

def parse_port_range(port_range):
    """è§£æç«¯å£èŒƒå›´å­—ç¬¦ä¸²"""
    try:
        if ',' in port_range:
            ports = set()
            parts = port_range.split(',')
            for part in parts:
                if '-' in part:
                    start, end = part.split('-')
                    ports.update(range(int(start), int(end) + 1))
                else:
                    ports.add(int(part))
            return sorted(ports)
        elif '-' in port_range:
            start, end = port_range.split('-')
            return list(range(int(start), int(end) + 1))
        else:
            return [int(port_range)]
    except ValueError:
        print("é”™è¯¯: ç«¯å£æ ¼å¼æ— æ•ˆ")
        sys.exit(1)

def resolve_hostname(hostname):
    """è§£æä¸»æœºåè·å–IPåœ°å€"""
    try:
        return socket.gethostbyname(hostname)
    except socket.gaierror:
        print(f"é”™è¯¯: æ— æ³•è§£æä¸»æœºå '{hostname}'")
        sys.exit(1)

def tcp_connect_scan(target_ip, port, timeout):
    """TCPè¿æ¥æ‰«æç«¯å£"""
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((target_ip, port))
        sock.close()
        return result == 0
    except socket.error:
        return False

def extract_title_from_html(html_content):
    """ä»HTMLå†…å®¹ä¸­æå–æ ‡é¢˜"""
    try:
        soup = BeautifulSoup(html_content, 'html.parser')
        title = soup.title.string
        if title:
            title = title.strip()
            # æ¸…ç†æ ‡é¢˜ä¸­çš„å¤šä½™ç©ºç™½å’Œæ¢è¡Œ
            title = re.sub(r'\s+', ' ', title)
            return title[:200]  # é™åˆ¶æ ‡é¢˜é•¿åº¦
    except:
        pass
    
    # å¦‚æœBeautifulSoupå¤±è´¥ï¼Œå°è¯•æ­£åˆ™è¡¨è¾¾å¼
    try:
        match = re.search(r'<title[^>]*>([^<]+)</title>', html_content, re.IGNORECASE)
        if match:
            title = match.group(1).strip()
            title = re.sub(r'\s+', ' ', title)
            return title[:200]
    except:
        pass
    
    return "No Title"

def probe_http_service(target_ip, port, timeout, verify_ssl=False, force_all=False):
    """æ¢æµ‹HTTP/HTTPSæœåŠ¡å¹¶è·å–è¯¦ç»†ä¿¡æ¯"""
    results = []
    
    # å®šä¹‰è¦å°è¯•çš„åè®®
    protocols = [
        ('http', 80, 8080, 8000, 3000, 8888, 8081, 8090, 5000, 5001, 5010, 5011, 8091, 8085, 8099, 8778, 8891, 9000, 28001, 28002, 28003, 28004, 50078, 60080, 60081),
        ('https', 443, 8443)
    ]
    
    for protocol, *common_ports in protocols:
        # å¦‚æœä¸æ˜¯å¸¸è§HTTPç«¯å£ä¸”æ²¡æœ‰å¼ºåˆ¶æ‰«æï¼Œè·³è¿‡
        if not force_all and port not in common_ports and protocol == 'http':
            if port not in COMMON_HTTP_PORTS:
                continue
        
        url = f"{protocol}://{target_ip}:{port}"
        
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'close',
                'Upgrade-Insecure-Requests': '1'
            }
            
            response = requests.get(
                url,
                timeout=timeout,
                verify=verify_ssl,
                headers=headers,
                allow_redirects=True
            )
            
            # è·å–æœåŠ¡å™¨ä¿¡æ¯
            server = response.headers.get('Server', 'Unknown')
            content_type = response.headers.get('Content-Type', 'Unknown')
            status_code = response.status_code
            
            # æå–æ ‡é¢˜
            title = "No Title"
            if 'text/html' in content_type.lower():
                try:
                    title = extract_title_from_html(response.text)
                except:
                    pass
            
            # å°è¯•è·å–å“åº”é•¿åº¦
            content_length = len(response.content) if response.content else 0
            
            result = {
                'url': url,
                'protocol': protocol,
                'port': port,
                'status_code': status_code,
                'title': title,
                'server': server,
                'content_type': content_type.split(';')[0],  # åªå–ä¸»ç±»å‹
                'content_length': content_length,
                'is_web_service': True
            }
            results.append(result)
            
        except requests.exceptions.SSLError:
            # SSLé”™è¯¯ï¼Œå¯èƒ½æ˜¯è‡ªç­¾åè¯ä¹¦ï¼Œå°è¯•HTTP
            continue
        except requests.exceptions.ConnectionError:
            continue
        except requests.exceptions.Timeout:
            continue
        except requests.exceptions.TooManyRedirects:
            continue
        except requests.exceptions.RequestException as e:
            continue
    
    return results

def get_service_name(port):
    """è·å–ç«¯å£å¯¹åº”çš„æœåŠ¡åç§°"""
    try:
        return socket.getservbyport(port, 'tcp')
    except:
        return "unknown"

def port_scan_worker(target_ip, port, timeout):
    """ç«¯å£æ‰«æå·¥ä½œçº¿ç¨‹"""
    if tcp_connect_scan(target_ip, port, timeout):
        service = get_service_name(port)
        return {'port': port, 'service': service, 'open': True}
    return {'port': port, 'service': 'unknown', 'open': False}

def scan_ports(target_ip, ports, thread_count, timeout):
    """å¤šçº¿ç¨‹ç«¯å£æ‰«æ"""
    open_ports = []
    print(f"[*] å¼€å§‹ç«¯å£æ‰«æ ({len(ports)} ä¸ªç«¯å£)...")
    
    with ThreadPoolExecutor(max_workers=thread_count) as executor:
        future_to_port = {
            executor.submit(port_scan_worker, target_ip, port, timeout): port 
            for port in ports
        }
        
        completed = 0
        for future in as_completed(future_to_port):
            try:
                result = future.result(timeout=timeout+1)
                if result['open']:
                    open_ports.append(result)
                    print(f"[+] å‘ç°å¼€æ”¾ç«¯å£: {target_ip}:{result['port']} ({result['service']})")
            except Exception as e:
                pass
            
            completed += 1
            if completed % 10 == 0:
                sys.stdout.write(f"\r[*] æ‰«æè¿›åº¦: {completed}/{len(ports)}")
                sys.stdout.flush()
    
    print(f"\n[*] ç«¯å£æ‰«æå®Œæˆï¼Œå‘ç° {len(open_ports)} ä¸ªå¼€æ”¾ç«¯å£")
    return open_ports

def http_probe_worker(target_ip, port_info, timeout, verify_ssl, force_all):
    """HTTPæ¢æµ‹å·¥ä½œçº¿ç¨‹"""
    http_results = []
    
    # å¯¹æ¯ä¸ªå¼€æ”¾ç«¯å£è¿›è¡ŒHTTPæ¢æµ‹
    port = port_info['port']
    results = probe_http_service(target_ip, port, timeout, verify_ssl, force_all)
    
    if results:
        for result in results:
            http_results.append(result)
    else:
        # å¦‚æœæ²¡æœ‰HTTPæœåŠ¡ï¼Œè¿”å›ç«¯å£ä¿¡æ¯
        http_results.append({
            'url': f"http://{target_ip}:{port}",
            'protocol': 'unknown',
            'port': port,
            'status_code': 0,
            'title': 'No HTTP Service',
            'server': 'Unknown',
            'content_type': 'Unknown',
            'content_length': 0,
            'is_web_service': False,
            'original_service': port_info['service']
        })
    
    return http_results

def probe_http_services(target_ip, open_ports, thread_count, timeout, verify_ssl, force_all):
    """å¤šçº¿ç¨‹HTTPæœåŠ¡æ¢æµ‹"""
    print(f"\n[*] å¼€å§‹HTTPæœåŠ¡æ¢æµ‹ ({len(open_ports)} ä¸ªç«¯å£)...")
    
    all_http_results = []
    
    with ThreadPoolExecutor(max_workers=thread_count) as executor:
        future_to_port = {
            executor.submit(http_probe_worker, target_ip, port_info, timeout, verify_ssl, force_all): port_info
            for port_info in open_ports
        }
        
        completed = 0
        for future in as_completed(future_to_port):
            try:
                results = future.result(timeout=timeout+2)
                for result in results:
                    if result.get('is_web_service', False):
                        all_http_results.append(result)
                        print(f"[HTTP] {result['url']} - çŠ¶æ€: {result['status_code']} - æ ‡é¢˜: {result['title']}")
            except Exception as e:
                pass
            
            completed += 1
            if completed % 5 == 0:
                sys.stdout.write(f"\r[*] HTTPæ¢æµ‹è¿›åº¦: {completed}/{len(open_ports)}")
                sys.stdout.flush()
    
    print(f"\n[*] HTTPæœåŠ¡æ¢æµ‹å®Œæˆ")
    return all_http_results

def display_results(target_ip, open_ports, http_results, show_all=False):
    """æ˜¾ç¤ºæ‰«æç»“æœ"""
    print("\n" + "="*100)
    print("æ‰«æç»“æœæ±‡æ€»")
    print("="*100)
    
    web_services = [r for r in http_results if r.get('is_web_service', False)]
    non_web_ports = [p for p in open_ports if p['port'] not in [r['port'] for r in web_services]]
    
    # æ˜¾ç¤ºWebæœåŠ¡
    if web_services:
        print("\n[WebæœåŠ¡å‘ç°]")
        print("-" * 100)
        for result in web_services:
            print(f"ğŸ”— {result['url']}")
            print(f"   â”œâ”€ çŠ¶æ€: {result['status_code']} | åè®®: {result['protocol']} | ç«¯å£: {result['port']}")
            print(f"   â”œâ”€ æ ‡é¢˜: {result['title']}")
            print(f"   â”œâ”€ æœåŠ¡å™¨: {result['server']}")
            print(f"   â”œâ”€ ç±»å‹: {result['content_type']}")
            print(f"   â””â”€ å¤§å°: {result.get('content_length', 0):,} å­—èŠ‚")
            print()
    
    # æ˜¾ç¤ºéWebæœåŠ¡çš„å¼€æ”¾ç«¯å£
    if show_all and non_web_ports:
        print("\n[éWebæœåŠ¡ç«¯å£]")
        print("-" * 100)
        for port_info in non_web_ports:
            url = f"http://{target_ip}:{port_info['port']}"
            print(f"ğŸ”Œ {url} ({port_info['service']}) - æ— HTTPå“åº”")
        print()
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("="*100)
    print(f"ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  ğŸ“¡ å¼€æ”¾ç«¯å£æ€»æ•°: {len(open_ports)} ä¸ª")
    print(f"  ğŸŒ WebæœåŠ¡å‘ç°: {len(web_services)} ä¸ª")
    print(f"  âš“ éWebæœåŠ¡ç«¯å£: {len(non_web_ports)} ä¸ª")
    print("="*100)
    
    return len(open_ports), len(web_services), len(non_web_ports)

def save_results(target_ip, open_ports, http_results, filename, show_all=False):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"HTTPæœåŠ¡æ¢æµ‹æ‰«ææŠ¥å‘Š\n")
            f.write(f"ç›®æ ‡: {target_ip}\n")
            f.write(f"æ‰«ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("="*80 + "\n\n")
            
            web_services = [r for r in http_results if r.get('is_web_service', False)]
            
            if web_services:
                f.write("[WebæœåŠ¡åˆ—è¡¨]\n")
                f.write("-"*80 + "\n")
                for result in web_services:
                    f.write(f"URL: {result['url']}\n")
                    f.write(f"çŠ¶æ€ç : {result['status_code']}\n")
                    f.write(f"åè®®: {result['protocol']} | ç«¯å£: {result['port']}\n")
                    f.write(f"æ ‡é¢˜: {result['title']}\n")
                    f.write(f"æœåŠ¡å™¨: {result['server']}\n")
                    f.write(f"å†…å®¹ç±»å‹: {result['content_type']}\n")
                    f.write(f"å†…å®¹é•¿åº¦: {result.get('content_length', 0):,} å­—èŠ‚\n")
                    f.write("-"*40 + "\n")
            
            if show_all:
                non_web_ports = [p for p in open_ports if p['port'] not in [r['port'] for r in web_services]]
                if non_web_ports:
                    f.write("\n[éWebæœåŠ¡ç«¯å£]\n")
                    f.write("-"*80 + "\n")
                    for port_info in non_web_ports:
                        f.write(f"{target_ip}:{port_info['port']} ({port_info['service']})\n")
            
            f.write(f"\n[ç»Ÿè®¡ä¿¡æ¯]\n")
            f.write(f"å¼€æ”¾ç«¯å£æ€»æ•°: {len(open_ports)} ä¸ª\n")
            f.write(f"WebæœåŠ¡å‘ç°: {len(web_services)} ä¸ª\n")
            f.write(f"æ‰«æå®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        print(f"\n[âœ“] ç»“æœå·²ä¿å­˜åˆ°: {filename}")
    except Exception as e:
        print(f"[!] é”™è¯¯: æ— æ³•ä¿å­˜æ–‡ä»¶ - {e}")

def main():
    """ä¸»å‡½æ•°"""
    signal.signal(signal.SIGINT, lambda s, f: (print("\n[!] æ‰«æè¢«ç”¨æˆ·ä¸­æ–­"), sys.exit(0)))
    
    # è§£æå‚æ•°
    args = parse_arguments()
    
    # è§£æç›®æ ‡ä¸»æœº
    target_ip = resolve_hostname(args.target)
    print(f"[*] ç›®æ ‡: {args.target} ({target_ip})")
    
    # è§£æç«¯å£èŒƒå›´
    ports_to_scan = parse_port_range(args.ports)
    print(f"[*] æ‰«æç«¯å£: {len(ports_to_scan)} ä¸ª")
    print(f"[*] ç«¯å£æ‰«æçº¿ç¨‹: {args.threads}")
    print(f"[*] HTTPæ¢æµ‹çº¿ç¨‹: {args.threads_http}")
    print(f"[*] å¼ºåˆ¶HTTPæ¢æµ‹: {'æ˜¯' if args.force_http else 'å¦'}")
    print(f"[*] SSLè¯ä¹¦éªŒè¯: {'å¯ç”¨' if not args.no_verify else 'ç¦ç”¨'}")
    
    start_time = time.time()
    
    # ç¬¬ä¸€é˜¶æ®µï¼šç«¯å£æ‰«æ
    open_ports = scan_ports(target_ip, ports_to_scan, args.threads, args.timeout_scan)
    
    if not open_ports:
        print("[!] æœªå‘ç°å¼€æ”¾ç«¯å£")
        return
    
    # ç¬¬äºŒé˜¶æ®µï¼šHTTPæœåŠ¡æ¢æµ‹
    http_results = probe_http_services(
        target_ip, 
        open_ports, 
        args.threads_http, 
        args.timeout_http, 
        not args.no_verify,
        args.force_http
    )
    
    # æ˜¾ç¤ºç»“æœ
    open_count, web_count, non_web_count = display_results(target_ip, open_ports, http_results, args.show_all)
    
    # è®¡ç®—æ‰«ææ—¶é—´
    scan_duration = time.time() - start_time
    print(f"[*] æ€»è€—æ—¶: {scan_duration:.2f} ç§’")
    
    # ä¿å­˜ç»“æœ
    if args.output:
        save_results(target_ip, open_ports, http_results, args.output, args.show_all)
    
    # ç”Ÿæˆå¯ç‚¹å‡»çš„é“¾æ¥
    print(f"\n[ğŸ”— WebæœåŠ¡é“¾æ¥åˆ—è¡¨]")
    for result in http_results:
        if result.get('is_web_service', False):
            print(f"  {result['url']}")

if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    try:
        import requests
        from bs4 import BeautifulSoup
    except ImportError as e:
        print(f"[!] ç¼ºå°‘ä¾èµ–åŒ…: {e}")
        print(f"[!] è¯·è¿è¡Œ: pip install requests beautifulsoup4")
        sys.exit(1)
    
    main()
